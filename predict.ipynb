{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70234869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the data\n",
    "df = pd.read_csv('data/games.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nColumn info:\")\n",
    "print(df.info())\n",
    "print(f\"\\nTarget variables stats:\")\n",
    "print(df[['away_score', 'home_score', 'total']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and feature engineering\n",
    "# Remove rows with missing critical values\n",
    "df_clean = df.dropna(subset=['away_score', 'home_score', 'away_team', 'home_team'])\n",
    "\n",
    "# Fill missing values in QB and coach names before using them\n",
    "df_clean['away_qb_name'] = df_clean['away_qb_name'].fillna('Unknown')\n",
    "df_clean['home_qb_name'] = df_clean['home_qb_name'].fillna('Unknown')\n",
    "df_clean['away_coach'] = df_clean['away_coach'].fillna('Unknown')\n",
    "df_clean['home_coach'] = df_clean['home_coach'].fillna('Unknown')\n",
    "\n",
    "# Extract features - EXPANDED with QB, coach, game type, weekday, division game, and betting odds\n",
    "features_to_use = ['season', 'week', 'away_rest', 'home_rest', 'temp', 'wind']\n",
    "categorical_features = ['away_team', 'home_team', 'roof', 'surface',\n",
    "                        'away_qb_name', 'home_qb_name', 'away_coach', 'home_coach',\n",
    "                        'game_type', 'weekday', 'div_game']\n",
    "numeric_features_new = ['over_odds', 'spread_line']  # Betting lines (pre-game consensus)\n",
    "\n",
    "# Create a working dataframe\n",
    "all_features = features_to_use + categorical_features + numeric_features_new\n",
    "X = df_clean[all_features].copy()\n",
    "y_away = df_clean['away_score'].copy()\n",
    "y_home = df_clean['home_score'].copy()\n",
    "y_total = df_clean['total'].copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "le_dict = {}\n",
    "for cat_feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X[cat_feature] = le.fit_transform(X[cat_feature].astype(str))\n",
    "    le_dict[cat_feature] = le\n",
    "\n",
    "# Fill missing values in numeric features\n",
    "X = X.fillna(X.mean(numeric_only=True))\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Features:\\n{X.head()}\")\n",
    "print(f\"\\nAwayScore - Mean: {y_away.mean():.1f}, Std: {y_away.std():.1f}\")\n",
    "print(f\"HomeScore - Mean: {y_home.mean():.1f}, Std: {y_home.std():.1f}\")\n",
    "print(f\"Total - Mean: {y_total.mean():.1f}, Std: {y_total.std():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of columns used in the model\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL INPUT FEATURES FROM GAMES.CSV\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define all used columns\n",
    "input_features = features_to_use + categorical_features + numeric_features_new\n",
    "target_columns = ['away_score', 'home_score', 'total']\n",
    "\n",
    "print(f\"\\nNUMERIC FEATURES ({len(features_to_use) + len(numeric_features_new)}):\")\n",
    "for feat in features_to_use + numeric_features_new:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "print(f\"\\nCATEGORICAL FEATURES ({len(categorical_features)}):\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "print(f\"\\nTARGET VARIABLES ({len(target_columns)}):\")\n",
    "for target in target_columns:\n",
    "    print(f\"  - {target}\")\n",
    "\n",
    "print(f\"\\nTOTAL FEATURES USED: {len(input_features) + len(target_columns)}\")\n",
    "\n",
    "# Show which columns from CSV were NOT used\n",
    "all_csv_columns = set(df.columns)\n",
    "used_columns = set(input_features + target_columns)\n",
    "unused_columns = all_csv_columns - used_columns\n",
    "\n",
    "if unused_columns:\n",
    "    print(f\"\\nCOLUMNS NOT USED IN MODEL ({len(unused_columns)}):\")\n",
    "    for col in sorted(unused_columns):\n",
    "        print(f\"  - {col}\")\n",
    "else:\n",
    "    print(\"\\nAll columns from CSV were used in the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdeceaa",
   "metadata": {},
   "source": [
    "## Expanded Model Features\n",
    "\n",
    "This version includes the high and moderate potential features for improved predictions:\n",
    "\n",
    "### Features Added (v2):\n",
    "**High Potential Categorical Features:**\n",
    "- QB names (away_qb_name, home_qb_name) - QB quality is critical to scoring\n",
    "- Coaches (away_coach, home_coach) - Coaching philosophy affects scoring patterns\n",
    "- Game type - Playoff games score differently than regular season\n",
    "- Weekday - Thursday/Monday night games have different scoring than Sunday\n",
    "- Division game - Rivalry effects may impact scoring\n",
    "\n",
    "**Moderate Potential Numeric Features:**\n",
    "- Betting odds (over_odds, spread_line) - Expert consensus on expected scoring\n",
    "\n",
    "### Model Improvement:\n",
    "The expanded feature set (21 total) should improve CV scores by capturing:\n",
    "- Individual QB impact (not just team identity)\n",
    "- Coaching philosophy variance\n",
    "- Game context (playoff vs regular season)\n",
    "- Expert market expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f507c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (80/20)\n",
    "X_train, X_test, y_away_train, y_away_test = train_test_split(X, y_away, test_size=0.2, random_state=42)\n",
    "_, _, y_home_train, y_home_test = train_test_split(X, y_home, test_size=0.2, random_state=42)\n",
    "_, _, y_total_train, y_total_test = train_test_split(X, y_total, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1038bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for away team score\n",
    "print(\"=== AWAY TEAM SCORE ===\")\n",
    "rf_away = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_away.fit(X_train, y_away_train)\n",
    "\n",
    "gb_away = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_away.fit(X_train, y_away_train)\n",
    "\n",
    "y_away_pred_rf = rf_away.predict(X_test)\n",
    "y_away_pred_gb = gb_away.predict(X_test)\n",
    "\n",
    "print(f\"Random Forest - MAE: {mean_absolute_error(y_away_test, y_away_pred_rf):.2f}, R²: {r2_score(y_away_test, y_away_pred_rf):.3f}\")\n",
    "print(f\"Gradient Boosting - MAE: {mean_absolute_error(y_away_test, y_away_pred_gb):.2f}, R²: {r2_score(y_away_test, y_away_pred_gb):.3f}\")\n",
    "\n",
    "# Train models for home team score\n",
    "print(\"\\n=== HOME TEAM SCORE ===\")\n",
    "rf_home = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_home.fit(X_train, y_home_train)\n",
    "\n",
    "gb_home = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_home.fit(X_train, y_home_train)\n",
    "\n",
    "y_home_pred_rf = rf_home.predict(X_test)\n",
    "y_home_pred_gb = gb_home.predict(X_test)\n",
    "\n",
    "print(f\"Random Forest - MAE: {mean_absolute_error(y_home_test, y_home_pred_rf):.2f}, R²: {r2_score(y_home_test, y_home_pred_rf):.3f}\")\n",
    "print(f\"Gradient Boosting - MAE: {mean_absolute_error(y_home_test, y_home_pred_gb):.2f}, R²: {r2_score(y_home_test, y_home_pred_gb):.3f}\")\n",
    "\n",
    "# Total score is calculated as sum of away + home (mathematical consistency)\n",
    "print(\"\\n=== TOTAL SCORE ===\")\n",
    "print(\"Total score is calculated as Away + Home predictions (no separate model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8d283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AWAY TEAM SCORE ===\n",
      "Random Forest - CV MAE: 7.83 (+/- 0.23)\n",
      "Gradient Boosting - CV MAE: 7.72 (+/- 0.18)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation scores (5-fold)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CROSS-VALIDATION SCORES (5-Fold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Away team score\n",
    "cv_rf_away = cross_val_score(rf_away, X, y_away, cv=5, scoring='neg_mean_absolute_error')\n",
    "cv_gb_away = cross_val_score(gb_away, X, y_away, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"\\n=== AWAY TEAM SCORE ===\")\n",
    "print(f\"Random Forest - CV MAE: {-cv_rf_away.mean():.2f} (+/- {cv_rf_away.std():.2f})\")\n",
    "print(f\"Gradient Boosting - CV MAE: {-cv_gb_away.mean():.2f} (+/- {cv_gb_away.std():.2f})\")\n",
    "\n",
    "# Home team score\n",
    "cv_rf_home = cross_val_score(rf_home, X, y_home, cv=5, scoring='neg_mean_absolute_error')\n",
    "cv_gb_home = cross_val_score(gb_home, X, y_home, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"\\n=== HOME TEAM SCORE ===\")\n",
    "print(f\"Random Forest - CV MAE: {-cv_rf_home.mean():.2f} (+/- {cv_rf_home.std():.2f})\")\n",
    "print(f\"Gradient Boosting - CV MAE: {-cv_gb_home.mean():.2f} (+/- {cv_gb_home.std():.2f})\")\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY: Cross-Validation Scores\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n(Total Score calculated as Away + Home, no separate model trained)\")\n",
    "cv_summary = pd.DataFrame({\n",
    "    'Target': ['Away Score', 'Away Score', 'Home Score', 'Home Score'],\n",
    "    'Model': ['RF', 'GB', 'RF', 'GB'],\n",
    "    'CV MAE': [-cv_rf_away.mean(), -cv_gb_away.mean(), -cv_rf_home.mean(), -cv_gb_home.mean()],\n",
    "    'CV Std': [cv_rf_away.std(), cv_gb_away.std(), cv_rf_home.std(), cv_gb_home.std()]\n",
    "})\n",
    "print(cv_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec3c810",
   "metadata": {},
   "source": [
    "## Understanding Cross-Validation Results\n",
    "\n",
    "**CV MAE (Cross-Validation Mean Absolute Error)** measures average prediction error when the model is tested on data it hasn't seen:\n",
    "- The number is the expected error in points for score predictions\n",
    "- The ± value (standard deviation) shows consistency across different data splits\n",
    "  - Smaller ± = more reliable predictions across different game scenarios\n",
    "  - Larger ± = predictions vary more depending on which games are used\n",
    "\n",
    "**Why it matters:** CV scores are more trustworthy than test set scores because they test on multiple different data subsets. A model that performs well on CV will generalize better to future games.\n",
    "\n",
    "**Interpretation of our results:**\n",
    "- **Gradient Boosting wins** across all targets (lower MAE = better)\n",
    "- **Consistency:** Home scores are most consistent (±0.14-0.16), suggesting home team conditions are predictable\n",
    "- **Difficulty:** Total score is harder to predict (11.3 MAE) vs individual scores (8.1 MAE)\n",
    "- **Practical:** Predictions will typically be within ±8-11 points of actual scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b257129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction for the target game: 2025_22_SEA_NE\n",
    "target_game_id = '2025_22_SEA_NE'\n",
    "\n",
    "# Look for the game in the dataset\n",
    "target_game = df_clean[df_clean['game_id'] == target_game_id]\n",
    "\n",
    "if not target_game.empty:\n",
    "    print(f\"Found game {target_game_id} in dataset\")\n",
    "    print(target_game[['away_team', 'home_team', 'away_score', 'home_score', 'total']])\n",
    "else:\n",
    "    print(f\"Game {target_game_id} not in historical data (upcoming game).\")\n",
    "    print(f\"Using trained models with synthesized features from recent games (2023+)...\\n\")\n",
    "    # For upcoming games not in dataset, we construct the feature vector\n",
    "    # Using recent season average values to estimate typical conditions\n",
    "\n",
    "    # Extract game components\n",
    "    parts = target_game_id.split('_')\n",
    "    season = int(parts[0])\n",
    "    week = int(parts[1])\n",
    "    away_team = parts[2]\n",
    "    home_team = parts[3]\n",
    "\n",
    "    # Get recent data to estimate values\n",
    "    recent_games = df_clean[df_clean['season'] >= 2023]\n",
    "    away_avg_rest = recent_games['away_rest'].mean()\n",
    "    home_avg_rest = recent_games['home_rest'].mean()\n",
    "    avg_temp = recent_games['temp'].mean()\n",
    "    avg_wind = recent_games['wind'].mean()\n",
    "\n",
    "    # Create feature vector for prediction with ALL features including new ones\n",
    "    # Get average betting odds from recent games\n",
    "    avg_over_odds = recent_games['over_odds'].mean() if 'over_odds' in recent_games.columns else 45.0\n",
    "    avg_spread_line = recent_games['spread_line'].mean() if 'spread_line' in recent_games.columns else 0.0\n",
    "\n",
    "    prediction_data = {\n",
    "        'season': [season],\n",
    "        'week': [week],\n",
    "        'away_rest': [away_avg_rest],\n",
    "        'home_rest': [home_avg_rest],\n",
    "        'temp': [avg_temp],\n",
    "        'wind': [avg_wind],\n",
    "        'away_team': [away_team],\n",
    "        'home_team': [home_team],\n",
    "        'roof': ['outdoors'],  # Default assumption\n",
    "        'surface': ['grass'],  # Default assumption\n",
    "        'away_qb_name': ['Unknown'],  # No specific QB data\n",
    "        'home_qb_name': ['Unknown'],  # No specific QB data\n",
    "        'away_coach': ['Unknown'],  # No specific coach data\n",
    "        'home_coach': ['Unknown'],  # No specific coach data\n",
    "        'game_type': ['REG'],  # Regular season default\n",
    "        'weekday': ['Sunday'],  # Most common NFL day\n",
    "        'div_game': ['0'],  # Not a division game by default (as string for categorical encoding)\n",
    "        'over_odds': [avg_over_odds],  # Average betting odds\n",
    "        'spread_line': [avg_spread_line]  # Average spread\n",
    "    }\n",
    "\n",
    "    prediction_df = pd.DataFrame(prediction_data)\n",
    "\n",
    "    # Encode categorical features using stored encoders\n",
    "    for cat_feature in categorical_features:\n",
    "        if cat_feature in le_dict:\n",
    "            # Handle unknown values\n",
    "            known_classes = list(le_dict[cat_feature].classes_)\n",
    "            value_to_encode = prediction_df[cat_feature].iloc[0]\n",
    "\n",
    "            # If value is unknown, use the first known class\n",
    "            if value_to_encode not in le_dict[cat_feature].classes_:\n",
    "                value_to_encode = known_classes[0]\n",
    "\n",
    "            prediction_df[cat_feature] = le_dict[cat_feature].transform([value_to_encode])\n",
    "\n",
    "    print(f\"\\nPrediction features for {target_game_id}:\")\n",
    "    print(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ensemble predictions for the target game\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SCORE PREDICTIONS FOR {target_game_id}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if not target_game.empty:\n",
    "    # Use the actual game data from dataset\n",
    "    game_features = target_game[features_to_use + categorical_features + numeric_features_new].copy()\n",
    "    for cat_feature in categorical_features:\n",
    "        game_features[cat_feature] = le_dict[cat_feature].transform(game_features[cat_feature].astype(str))\n",
    "else:\n",
    "    game_features = prediction_df\n",
    "\n",
    "# Get predictions from both models\n",
    "away_score_rf = rf_away.predict(game_features)[0]\n",
    "away_score_gb = gb_away.predict(game_features)[0]\n",
    "away_score_ensemble = (away_score_rf + away_score_gb) / 2\n",
    "\n",
    "home_score_rf = rf_home.predict(game_features)[0]\n",
    "home_score_gb = gb_home.predict(game_features)[0]\n",
    "home_score_ensemble = (home_score_rf + home_score_gb) / 2\n",
    "\n",
    "# Calculate total as sum of individual scores (mathematical consistency)\n",
    "total_score_rf = away_score_rf + home_score_rf\n",
    "total_score_gb = away_score_gb + home_score_gb\n",
    "total_score_ensemble = away_score_ensemble + home_score_ensemble\n",
    "\n",
    "print(f\"\\n{'ENSEMBLE PREDICTION (Average of RF & GB):':<40}\")\n",
    "print(f\"  Away Team (SEA) Score: {away_score_ensemble:.1f} points\")\n",
    "print(f\"  Home Team (NE) Score:  {home_score_ensemble:.1f} points\")\n",
    "print(f\"  Total Score:           {total_score_ensemble:.1f} points (Away + Home)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3dd491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model comparison\n",
    "# Extract team abbreviations from target_game_id\n",
    "game_parts = target_game_id.split('_')\n",
    "away_abbr = game_parts[2]\n",
    "home_abbr = game_parts[3]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\n{'Metric':<20} {'Random Forest':<20} {'Gradient Boost':<20} {'Ensemble':<15}\")\n",
    "print(f\"{'-'*75}\")\n",
    "print(f\"{away_abbr + ' Score':<20} {away_score_rf:<20.1f} {away_score_gb:<20.1f} {away_score_ensemble:<15.1f}\")\n",
    "print(f\"{home_abbr + ' Score':<20} {home_score_rf:<20.1f} {home_score_gb:<20.1f} {home_score_ensemble:<15.1f}\")\n",
    "print(f\"{'Total Score':<20} {total_score_rf:<20.1f} {total_score_gb:<20.1f} {total_score_ensemble:<15.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11570f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature importance\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FEATURE IMPORTANCE (Random Forest)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "feature_names = features_to_use + numeric_features_new + categorical_features\n",
    "rf_importance_away = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf_away.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nAway Score - Top 10 Features:\")\n",
    "print(rf_importance_away.head(10))\n",
    "\n",
    "rf_importance_home = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf_home.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nHome Score - Top 10 Features:\")\n",
    "print(rf_importance_home.head(10))\n",
    "\n",
    "print(f\"\\n(Total Score is calculated as Away + Home, not independently modeled)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfl-score-predict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
